{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class label counts: [1500 1500]\n",
      "X.shape: (3000, 502)\n",
      "y.shape: (3000,)\n"
     ]
    }
   ],
   "source": [
    "##########################\n",
    "### DATASET\n",
    "##########################\n",
    "\n",
    "# Load data\n",
    "with open('training_data.json', 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "data = np.array(data)\n",
    "\n",
    "X = data.astype(np.float32)\n",
    "y = np.array([1] * 1500 + [0] * 1500, dtype=np.int64)\n",
    "\n",
    "\n",
    "print('Class label counts:', np.bincount(y))\n",
    "print('X.shape:', X.shape)\n",
    "print('y.shape:', y.shape)\n",
    "\n",
    "# Shuffling & train/test split\n",
    "shuffle_idx = np.arange(y.shape[0])\n",
    "shuffle_rng = np.random.default_rng(123)\n",
    "shuffle_rng.shuffle(shuffle_idx)\n",
    "X, y = X[shuffle_idx], y[shuffle_idx]\n",
    "\n",
    "# 70/30 split\n",
    "split = int(0.7 * y.shape[0])\n",
    "X_train, X_test = X[shuffle_idx[:split]], X[shuffle_idx[split:]]\n",
    "y_train, y_test = y[shuffle_idx[:split]], y[shuffle_idx[split:]]\n",
    "\n",
    "# Normalize (mean zero, unit variance)\n",
    "# mu, sigma = X_train.mean(axis=0), X_train.std(axis=0)\n",
    "# X_train = (X_train - mu) / sigma\n",
    "# X_test = (X_test - mu) / sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Perceptron():\n",
    "    def __init__(self, num_features):\n",
    "        self.num_features = num_features\n",
    "        self.weights = torch.zeros(num_features, 1, \n",
    "                                   dtype=torch.float32)\n",
    "        self.bias = torch.zeros(1, dtype=torch.float32)\n",
    "        \n",
    "        # placeholder vectors so they don't\n",
    "        # need to be recreated each time\n",
    "        self.ones = torch.ones(1)\n",
    "        self.zeros = torch.zeros(1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        linear = torch.mm(x, self.weights) + self.bias\n",
    "        predictions = torch.where(linear > 0., self.ones, self.zeros)\n",
    "        return predictions\n",
    "        \n",
    "    def backward(self, x, y):  \n",
    "        predictions = self.forward(x)\n",
    "        errors = y - predictions\n",
    "        return errors\n",
    "        \n",
    "    def train(self, x, y, epochs):\n",
    "        for e in range(epochs):\n",
    "            for i in range(y.shape[0]):\n",
    "                # Reshape inputs to maintain proper dimensions\n",
    "                errors = self.backward(x[i].reshape(1, self.num_features), y[i]).reshape(-1)\n",
    "                self.weights += (errors * x[i]).reshape(self.num_features, 1)\n",
    "                self.bias += errors\n",
    "\n",
    "            acc = self.evaluate(x, y)\n",
    "            print('Test set accuracy: %.2f%%' % (acc*100))\n",
    "                            \n",
    "    def evaluate(self, x, y):\n",
    "        predictions = self.forward(x).reshape(-1)\n",
    "        accuracy = torch.sum(predictions == y).float() / y.shape[0]\n",
    "        return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy: 99.81%\n",
      "Test set accuracy: 100.00%\n",
      "Test set accuracy: 100.00%\n",
      "Test set accuracy: 100.00%\n",
      "Test set accuracy: 100.00%\n",
      "Test set accuracy: 100.00%\n",
      "Test set accuracy: 100.00%\n",
      "Test set accuracy: 100.00%\n",
      "Test set accuracy: 100.00%\n",
      "Test set accuracy: 100.00%\n",
      "Test set accuracy: 100.00%\n",
      "Test set accuracy: 100.00%\n",
      "Test set accuracy: 100.00%\n",
      "Test set accuracy: 100.00%\n",
      "Test set accuracy: 100.00%\n",
      "Test set accuracy: 100.00%\n",
      "Test set accuracy: 100.00%\n",
      "Test set accuracy: 100.00%\n",
      "Test set accuracy: 100.00%\n",
      "Test set accuracy: 100.00%\n",
      "Test set accuracy: 100.00%\n",
      "Test set accuracy: 100.00%\n",
      "Test set accuracy: 100.00%\n",
      "Test set accuracy: 100.00%\n",
      "Test set accuracy: 100.00%\n",
      "Test set accuracy: 100.00%\n",
      "Test set accuracy: 100.00%\n",
      "Test set accuracy: 100.00%\n",
      "Test set accuracy: 100.00%\n",
      "Test set accuracy: 100.00%\n",
      "Test set accuracy: 100.00%\n",
      "Test set accuracy: 100.00%\n",
      "Test set accuracy: 100.00%\n",
      "Test set accuracy: 100.00%\n",
      "Test set accuracy: 100.00%\n",
      "Test set accuracy: 100.00%\n",
      "Test set accuracy: 100.00%\n",
      "Test set accuracy: 100.00%\n",
      "Test set accuracy: 100.00%\n",
      "Test set accuracy: 100.00%\n",
      "Test set accuracy: 100.00%\n",
      "Test set accuracy: 100.00%\n",
      "Test set accuracy: 100.00%\n",
      "Test set accuracy: 100.00%\n",
      "Test set accuracy: 100.00%\n",
      "Test set accuracy: 100.00%\n",
      "Test set accuracy: 100.00%\n",
      "Test set accuracy: 100.00%\n",
      "Test set accuracy: 100.00%\n",
      "Test set accuracy: 100.00%\n",
      "Test set accuracy: 100.00%\n",
      "Test set accuracy: 100.00%\n",
      "Test set accuracy: 100.00%\n",
      "Test set accuracy: 100.00%\n",
      "Test set accuracy: 100.00%\n",
      "Test set accuracy: 100.00%\n",
      "Test set accuracy: 100.00%\n",
      "Test set accuracy: 100.00%\n",
      "Test set accuracy: 100.00%\n",
      "Test set accuracy: 100.00%\n",
      "Test set accuracy: 100.00%\n",
      "Test set accuracy: 100.00%\n",
      "Test set accuracy: 100.00%\n",
      "Test set accuracy: 100.00%\n",
      "Test set accuracy: 100.00%\n",
      "Test set accuracy: 100.00%\n",
      "Test set accuracy: 100.00%\n",
      "Test set accuracy: 100.00%\n",
      "Test set accuracy: 100.00%\n",
      "Test set accuracy: 100.00%\n",
      "Test set accuracy: 100.00%\n",
      "Test set accuracy: 100.00%\n",
      "Test set accuracy: 100.00%\n",
      "Test set accuracy: 100.00%\n",
      "Test set accuracy: 100.00%\n",
      "Test set accuracy: 100.00%\n",
      "Test set accuracy: 100.00%\n",
      "Test set accuracy: 100.00%\n",
      "Test set accuracy: 100.00%\n",
      "Test set accuracy: 100.00%\n",
      "Test set accuracy: 100.00%\n",
      "Test set accuracy: 100.00%\n",
      "Test set accuracy: 100.00%\n",
      "Test set accuracy: 100.00%\n",
      "Test set accuracy: 100.00%\n",
      "Test set accuracy: 100.00%\n",
      "Test set accuracy: 100.00%\n",
      "Test set accuracy: 100.00%\n",
      "Test set accuracy: 100.00%\n",
      "Test set accuracy: 100.00%\n",
      "Test set accuracy: 100.00%\n",
      "Test set accuracy: 100.00%\n",
      "Test set accuracy: 100.00%\n",
      "Test set accuracy: 100.00%\n",
      "Test set accuracy: 100.00%\n",
      "Test set accuracy: 100.00%\n",
      "Test set accuracy: 100.00%\n",
      "Test set accuracy: 100.00%\n",
      "Test set accuracy: 100.00%\n",
      "Test set accuracy: 100.00%\n"
     ]
    }
   ],
   "source": [
    "ppn = Perceptron(num_features=X_train.shape[1])\n",
    "\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.float32)\n",
    "\n",
    "ppn.train(X_train_tensor, y_train_tensor, epochs=100)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('model.json', 'w') as f:\n",
    "    json.dump({'weights': [x[0] for x in ppn.weights.tolist()], 'bias': ppn.bias.item()}, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive Case\n",
      "0 951.0\n",
      "1 951.0\n",
      "2 890.0\n",
      "3 879.0\n",
      "4 863.0\n",
      "5 861.0\n",
      "6 775.0\n",
      "7 721.0\n",
      "8 691.0\n",
      "9 688.0\n",
      "10 638.0\n",
      "11 620.0\n",
      "12 638.0\n",
      "13 656.0\n",
      "14 574.0\n",
      "15 579.0\n",
      "16 592.0\n",
      "17 564.0\n",
      "18 555.0\n",
      "19 502.0\n",
      "20 563.0\n",
      "21 528.0\n",
      "22 534.0\n",
      "23 482.0\n",
      "24 438.0\n",
      "25 481.0\n",
      "26 467.0\n",
      "27 474.0\n",
      "28 456.0\n",
      "29 453.0\n",
      "30 439.0\n",
      "31 442.0\n",
      "32 435.0\n",
      "33 398.0\n",
      "34 427.0\n",
      "35 448.0\n",
      "36 450.0\n",
      "37 438.0\n",
      "38 443.0\n",
      "39 432.0\n",
      "40 436.0\n",
      "41 418.0\n",
      "42 468.0\n",
      "43 400.0\n",
      "44 403.0\n",
      "45 432.0\n",
      "46 370.0\n",
      "47 407.0\n",
      "48 439.0\n",
      "49 435.0\n",
      "50 458.0\n",
      "51 455.0\n",
      "52 535.0\n",
      "53 563.0\n",
      "54 576.0\n",
      "55 561.0\n",
      "56 592.0\n",
      "57 585.0\n",
      "58 598.0\n",
      "59 592.0\n",
      "60 624.0\n",
      "61 698.0\n",
      "62 752.0\n",
      "63 758.0\n",
      "64 725.0\n",
      "65 823.0\n",
      "66 809.0\n",
      "67 806.0\n",
      "68 818.0\n",
      "69 865.0\n",
      "70 870.0\n",
      "71 867.0\n",
      "72 878.0\n",
      "73 880.0\n",
      "74 987.0\n",
      "75 946.0\n",
      "76 874.0\n",
      "77 899.0\n",
      "78 903.0\n",
      "79 898.0\n",
      "80 902.0\n",
      "81 907.0\n",
      "82 895.0\n",
      "83 903.0\n",
      "84 912.0\n",
      "85 900.0\n",
      "86 935.0\n",
      "87 933.0\n",
      "88 912.0\n",
      "89 988.0\n",
      "90 913.0\n",
      "91 917.0\n",
      "92 909.0\n",
      "93 947.0\n",
      "94 802.0\n",
      "95 775.0\n",
      "96 755.0\n",
      "97 727.0\n",
      "98 754.0\n",
      "99 738.0\n",
      "100 743.0\n",
      "101 755.0\n",
      "102 704.0\n",
      "103 630.0\n",
      "104 559.0\n",
      "105 587.0\n",
      "106 559.0\n",
      "107 535.0\n",
      "108 507.0\n",
      "109 451.0\n",
      "110 479.0\n",
      "111 463.0\n",
      "112 476.0\n",
      "113 460.0\n",
      "114 399.0\n",
      "115 434.0\n",
      "116 386.0\n",
      "117 425.0\n",
      "118 416.0\n",
      "119 500.0\n",
      "120 372.0\n",
      "121 415.0\n",
      "122 425.0\n",
      "123 387.0\n",
      "124 419.0\n",
      "125 403.0\n",
      "126 400.0\n",
      "127 415.0\n",
      "128 417.0\n",
      "129 397.0\n",
      "130 395.0\n",
      "131 402.0\n",
      "132 380.0\n",
      "133 384.0\n",
      "134 369.0\n",
      "135 346.0\n",
      "136 401.0\n",
      "137 400.0\n",
      "138 418.0\n",
      "139 399.0\n",
      "140 418.0\n",
      "141 412.0\n",
      "142 423.0\n",
      "143 380.0\n",
      "144 448.0\n",
      "145 462.0\n",
      "146 487.0\n",
      "147 483.0\n",
      "148 576.0\n",
      "149 619.0\n",
      "150 629.0\n",
      "151 648.0\n",
      "152 658.0\n",
      "153 711.0\n",
      "154 743.0\n",
      "155 755.0\n",
      "156 752.0\n",
      "157 813.0\n",
      "158 826.0\n",
      "159 816.0\n",
      "160 826.0\n",
      "161 805.0\n",
      "162 884.0\n",
      "163 839.0\n",
      "164 844.0\n",
      "165 885.0\n",
      "166 894.0\n",
      "167 846.0\n",
      "168 895.0\n",
      "169 824.0\n",
      "170 896.0\n",
      "171 853.0\n",
      "172 881.0\n",
      "173 830.0\n",
      "174 906.0\n",
      "175 896.0\n",
      "176 854.0\n",
      "177 883.0\n",
      "178 878.0\n",
      "179 889.0\n",
      "180 874.0\n",
      "181 914.0\n",
      "182 904.0\n",
      "183 897.0\n",
      "184 890.0\n",
      "185 892.0\n",
      "186 880.0\n",
      "187 891.0\n",
      "188 848.0\n",
      "189 816.0\n",
      "190 724.0\n",
      "191 673.0\n",
      "192 640.0\n",
      "193 619.0\n",
      "194 578.0\n",
      "195 539.0\n",
      "196 547.0\n",
      "197 543.0\n",
      "198 495.0\n",
      "199 477.0\n",
      "200 478.0\n",
      "201 432.0\n",
      "202 437.0\n",
      "203 410.0\n",
      "204 430.0\n",
      "205 413.0\n",
      "206 419.0\n",
      "207 399.0\n",
      "208 422.0\n",
      "209 410.0\n",
      "210 438.0\n",
      "211 446.0\n",
      "212 400.0\n",
      "213 342.0\n",
      "214 411.0\n",
      "215 427.0\n",
      "216 368.0\n",
      "217 384.0\n",
      "218 322.0\n",
      "219 370.0\n",
      "220 381.0\n",
      "221 368.0\n",
      "222 354.0\n",
      "223 369.0\n",
      "224 383.0\n",
      "225 371.0\n",
      "226 375.0\n",
      "227 368.0\n",
      "228 370.0\n",
      "229 431.0\n",
      "230 378.0\n",
      "231 382.0\n",
      "232 378.0\n",
      "233 411.0\n",
      "234 401.0\n",
      "235 417.0\n",
      "236 464.0\n",
      "237 511.0\n",
      "238 773.0\n",
      "239 746.0\n",
      "240 773.0\n",
      "241 787.0\n",
      "242 785.0\n",
      "243 848.0\n",
      "244 832.0\n",
      "245 816.0\n",
      "246 848.0\n",
      "247 862.0\n",
      "248 835.0\n",
      "249 873.0\n",
      "250 863.0\n",
      "251 864.0\n",
      "252 862.0\n",
      "253 915.0\n",
      "254 934.0\n",
      "255 905.0\n",
      "256 955.0\n",
      "257 889.0\n",
      "258 912.0\n",
      "259 893.0\n",
      "260 893.0\n",
      "261 883.0\n",
      "262 912.0\n",
      "263 907.0\n",
      "264 869.0\n",
      "265 899.0\n",
      "266 880.0\n",
      "267 770.0\n",
      "268 786.0\n",
      "269 683.0\n",
      "270 624.0\n",
      "271 672.0\n",
      "272 611.0\n",
      "273 573.0\n",
      "274 561.0\n",
      "275 532.0\n",
      "276 505.0\n",
      "277 492.0\n",
      "278 549.0\n",
      "279 464.0\n",
      "280 432.0\n",
      "281 458.0\n",
      "282 445.0\n",
      "283 458.0\n",
      "284 511.0\n",
      "285 432.0\n",
      "286 430.0\n",
      "287 422.0\n",
      "288 401.0\n",
      "289 416.0\n",
      "290 409.0\n",
      "291 403.0\n",
      "292 390.0\n",
      "293 429.0\n",
      "294 419.0\n",
      "295 400.0\n",
      "296 400.0\n",
      "297 384.0\n",
      "298 395.0\n",
      "299 383.0\n",
      "300 425.0\n",
      "301 402.0\n",
      "302 379.0\n",
      "303 368.0\n",
      "304 407.0\n",
      "305 368.0\n",
      "306 373.0\n",
      "307 343.0\n",
      "308 380.0\n",
      "309 342.0\n",
      "310 446.0\n",
      "311 359.0\n",
      "312 347.0\n",
      "313 416.0\n",
      "314 430.0\n",
      "315 447.0\n",
      "316 456.0\n",
      "317 510.0\n",
      "318 464.0\n",
      "319 614.0\n",
      "320 618.0\n",
      "321 613.0\n",
      "322 595.0\n",
      "323 631.0\n",
      "324 623.0\n",
      "325 642.0\n",
      "326 713.0\n",
      "327 730.0\n",
      "328 753.0\n",
      "329 751.0\n",
      "330 835.0\n",
      "331 802.0\n",
      "332 769.0\n",
      "333 805.0\n",
      "334 845.0\n",
      "335 847.0\n",
      "336 858.0\n",
      "337 849.0\n",
      "338 867.0\n",
      "339 880.0\n",
      "340 880.0\n",
      "341 880.0\n",
      "342 877.0\n",
      "343 886.0\n",
      "344 890.0\n",
      "345 860.0\n",
      "346 883.0\n",
      "347 869.0\n",
      "348 899.0\n",
      "349 907.0\n",
      "350 941.0\n",
      "351 850.0\n",
      "352 894.0\n",
      "353 912.0\n",
      "354 931.0\n",
      "355 878.0\n",
      "356 847.0\n",
      "357 847.0\n",
      "358 828.0\n",
      "359 757.0\n",
      "360 633.0\n",
      "361 640.0\n",
      "362 625.0\n",
      "363 617.0\n",
      "364 601.0\n",
      "365 635.0\n",
      "366 642.0\n",
      "367 576.0\n",
      "368 529.0\n",
      "369 539.0\n",
      "370 499.0\n",
      "371 500.0\n",
      "372 464.0\n",
      "373 448.0\n",
      "374 407.0\n",
      "375 447.0\n",
      "376 463.0\n",
      "377 431.0\n",
      "378 421.0\n",
      "379 405.0\n",
      "380 390.0\n",
      "381 379.0\n",
      "382 459.0\n",
      "383 423.0\n",
      "384 384.0\n",
      "385 403.0\n",
      "386 388.0\n",
      "387 379.0\n",
      "388 384.0\n",
      "389 384.0\n",
      "390 375.0\n",
      "391 366.0\n",
      "392 363.0\n",
      "393 352.0\n",
      "394 379.0\n",
      "395 342.0\n",
      "396 325.0\n",
      "397 369.0\n",
      "398 369.0\n",
      "399 401.0\n",
      "400 368.0\n",
      "401 384.0\n",
      "402 386.0\n",
      "403 394.0\n",
      "404 391.0\n",
      "405 379.0\n",
      "406 448.0\n",
      "407 439.0\n",
      "408 577.0\n",
      "409 531.0\n",
      "410 593.0\n",
      "411 638.0\n",
      "412 689.0\n",
      "413 638.0\n",
      "414 688.0\n",
      "415 817.0\n",
      "416 765.0\n",
      "417 833.0\n",
      "418 782.0\n",
      "419 850.0\n",
      "420 820.0\n",
      "421 799.0\n",
      "422 859.0\n",
      "423 849.0\n",
      "424 833.0\n",
      "425 827.0\n",
      "426 860.0\n",
      "427 853.0\n",
      "428 823.0\n",
      "429 828.0\n",
      "430 865.0\n",
      "431 874.0\n",
      "432 857.0\n",
      "433 897.0\n",
      "434 854.0\n",
      "435 865.0\n",
      "436 908.0\n",
      "437 896.0\n",
      "438 885.0\n",
      "439 907.0\n",
      "440 894.0\n",
      "441 884.0\n",
      "442 902.0\n",
      "443 897.0\n",
      "444 892.0\n",
      "445 880.0\n",
      "446 893.0\n",
      "447 855.0\n",
      "448 765.0\n",
      "449 761.0\n",
      "450 708.0\n",
      "451 704.0\n",
      "452 642.0\n",
      "453 617.0\n",
      "454 577.0\n",
      "455 560.0\n",
      "456 522.0\n",
      "457 490.0\n",
      "458 482.0\n",
      "459 447.0\n",
      "460 460.0\n",
      "461 451.0\n",
      "462 431.0\n",
      "463 433.0\n",
      "464 444.0\n",
      "465 446.0\n",
      "466 403.0\n",
      "467 439.0\n",
      "468 407.0\n",
      "469 390.0\n",
      "470 397.0\n",
      "471 394.0\n",
      "472 383.0\n",
      "473 384.0\n",
      "474 356.0\n",
      "475 393.0\n",
      "476 368.0\n",
      "477 368.0\n",
      "478 372.0\n",
      "479 379.0\n",
      "480 363.0\n",
      "481 357.0\n",
      "482 364.0\n",
      "483 368.0\n",
      "484 369.0\n",
      "485 362.0\n",
      "486 370.0\n",
      "487 356.0\n",
      "488 418.0\n",
      "489 364.0\n",
      "490 359.0\n",
      "491 361.0\n",
      "492 354.0\n",
      "493 385.0\n",
      "494 410.0\n",
      "495 422.0\n",
      "496 423.0\n",
      "497 454.0\n",
      "498 551.0\n",
      "499 592.0\n",
      "500 988.0\n",
      "501 322.0\n",
      "Negative Case\n",
      "[  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.  14.   0.   0.   0.   0.  17.   0.   0.  26.  13.\n",
      "  16.   0.   0.  39.   5.   9.  23.  33.   0.   8.  22.  16.  45.  50.\n",
      "  64.  72.  71.  80. 101. 106. 118. 144. 134. 139. 132. 142. 141. 175.\n",
      " 154. 163. 158. 167. 164. 214. 160. 161. 178. 175. 158. 166. 176. 156.\n",
      " 159. 166. 177. 162. 195. 149. 165. 176. 191. 187. 198. 191. 185. 171.\n",
      " 182. 208. 198. 213. 184. 208. 208. 210. 212. 243. 208. 230. 228. 229.\n",
      " 207. 237. 208. 235. 226. 246. 231. 230. 231. 246. 253. 243. 266. 243.\n",
      " 266. 255. 250. 246. 246. 267. 260. 272. 275. 276. 289. 295. 294. 301.\n",
      " 326. 307. 303. 291. 309. 331. 310. 314. 302. 283. 291. 287. 286. 304.\n",
      " 368. 304. 315. 311. 310. 281. 298. 295. 253. 304. 284. 268. 276. 278.\n",
      " 303. 295. 275. 259. 247. 245. 240. 206. 231. 225. 208. 182. 189. 175.\n",
      " 177. 151. 150. 139. 111. 118. 112.  80.  79.  70.  67.  66.  45.  28.\n",
      "  48.  65.  48.   0.  14.  12.   0.   0.   3.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  13.   0.   0.   0.\n",
      "   0.   0.   0.  12.   0.   3.   0.   0.  22.  21.   0.  13.  18.  16.\n",
      "  12.  16.   9.  21.  48.  41.  49.  48.  50.  77.  86.  90.  93. 125.\n",
      " 117. 118.  85. 144. 144. 149. 170. 161. 176. 170. 177. 190. 202. 214.\n",
      " 268. 214. 213. 235. 218. 209. 218. 210. 223. 225. 226. 240. 197. 279.\n",
      " 274. 287. 280. 279. 289. 298. 290. 304. 253. 315. 309. 323. 330. 344.\n",
      " 371. 357. 339. 344. 358. 336. 352. 339. 337. 353. 339. 337. 339. 339.\n",
      " 347. 368. 351. 353. 342. 351. 341. 353. 338. 331. 320. 304. 335. 304.\n",
      " 291. 289. 279. 308. 259. 283. 253. 261. 270. 240. 218. 202. 194. 177.\n",
      " 155. 176. 158. 191. 157. 144. 128. 122. 133. 125. 114. 114.  95.  83.\n",
      "  75.  81.  81.  93.  83.  80.  69.  78.  61.  53.  74.  64.  65.  59.\n",
      "  48.  38.  48.  25.  47.  55.  44.  63.  41.  38.  16.  18.  16.  42.\n",
      "  38.  23.  16.  32.  16.  19.  48.  14.  12.  14.  18.   0.  14.  27.\n",
      "  27.   0.  29.  12.  17.   9.   0.  19.  16.  27.  32.  26.  13.  33.\n",
      "  26.  31.  73.  34.  18.  14.  26.   0.  21.   8.  11.  12.   9.   0.\n",
      "   0.  35.  15.  16.  15.  14.   0.   4.   8.   5. 371.   0.]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "write() argument must be str, not int",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[34], line 22\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx, num \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(negative_case):\n\u001b[0;32m     21\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m idx \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(negative_case) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m---> 22\u001b[0m         f\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;28mint\u001b[39m(num))\n\u001b[0;32m     23\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     24\u001b[0m         f\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;28mstr\u001b[39m((\u001b[38;5;28mint\u001b[39m(num))) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mTypeError\u001b[0m: write() argument must be str, not int"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "print('Positive Case')\n",
    "positive_case = X_test[y_test == 1][random.randint(0, 299)]\n",
    "\n",
    "with open('positive_case.text', 'w') as f:\n",
    "    for idx, num in enumerate(positive_case):\n",
    "        print(idx, num)\n",
    "        if idx == len(positive_case) - 1:\n",
    "            f.write(str((int(num))))\n",
    "        else:\n",
    "            f.write(str((int(num))) + ',\\n')\n",
    "\n",
    "\n",
    "print('Negative Case')\n",
    "negative_case = X_test[y_test == 0][random.randint(0, 299)]\n",
    "print(negative_case)\n",
    "\n",
    "with open('negative_case.text', 'w') as f:\n",
    "    for idx, num in enumerate(negative_case):\n",
    "        if idx == len(negative_case) - 1:\n",
    "            f.write(int(num))\n",
    "        else:\n",
    "            f.write(str((int(num))) + ',\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy: 100.00%\n"
     ]
    }
   ],
   "source": [
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.float32)\n",
    "\n",
    "test_acc = ppn.evaluate(X_test_tensor, y_test_tensor)\n",
    "print('Test set accuracy: %.2f%%' % (test_acc*100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
